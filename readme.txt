User-Friendly Network Bending
Aaron Basch
Abstract
Network bending is an emerging method for active divergence through direct manipulation of neural networks’ internal components. This technique is both an artistic tool as well as a way to better understand what is typically a black box. Previous work requires expertise in order to fully utilize network bending due to confusing user-interface design choices. This project enables anyone to use these techniques through a user-friendly interface.

1	Introduction
Using neural networks as artistic tools is a popular research focus. Some benefits of neural networks are: they are capable of complex, non-linear transformations like timbre transfer, and generally can be helpful in sparking and assisting in the creation of new ideas. These benefits result in some tradeoffs, most notably that neural networks are often black boxes, where users only have control of the input, not the inner components. Most people have no idea what’s going on inside the box, and this can feel a bit like guess work. Additionally, outputs of generative neural nets are typically restricted to the data distribution present at training.
‘Network bending’ is a term coined by Broad et al.[1], where the goal is to manipulate the internal components of generative neural networks to achieve outputs outside of the training distribution. Broad’s work applies network bending to StyleGan2, and the idea has recently been extended to the audio domain. While the results of these approaches are intriguing, they lack an intuitive user-interface where non-experts could interact effectively within the network bending framework.
The goal of this work is twofold: to enable someone with little prior knowledge on machine learning to gain an understanding of the internal structure of a generative neural network through creative play; and also, to implement neural bending as an audio fx tool for musical artists. This project aims to create a user-friendly interface for network bending, along with implementing some new transformations that weren’t included in past work. 

2	Prior Work
Broad introduced network bending as a method for generative neural networks to break out of their training distribution by transforming the model’s internal structures directly. The term borrows from the world of circuit bending, a creative audio technique where one directly manipulates the circuit board on a synthesizer to create sounds that were previously unattainable through the standard interface. Broad takes this concept of creatively tampering with the generative system’s internal structure and applies it to StyleGan2, a popular generative adversarial network for image generation. The work is part of a larger movement called “active divergence”, in which creatives manipulate, tweak, and break generative tools in order to explore sounds that would normally be out of reach. In addition to network bending, other examples of active divergence include latent-space traversal (popular in GANs), cross-domain sampling in which datasets are blended together to create interesting training phenomenon, and loss hacking, where objectives are changed in order to achieve interesting results.
Broad’s implementation of network bending incorporates clustering and a variety of modifiable transformations. These include numerical transformations like ablation (zeroing), scalar multiplication, inversion, binary thresholding; affine transformations like translation, horizontal/vertical reflection, scaling, and rotation; as well as morphological transformations such as erosion and dilation.
Broad’s work achieves interesting image examples that were clear deviations from what we typically see in GANs. While one of the Broad’s motivations was to illuminate the inner workings of the black box model, there was little mention of a user interface and the individual components of the model remained somewhat opaque.
McCallum et al.[2] extend network bending to the audio domain, applying transformations to Magenta’s DDSP timbre transfer model, achieving similarly interesting results. A main difference in McCallum’s work is the addition of a user interface that anyone can download and try out. While this is an improvement, the interface is visually cluttered and potentially confusing for people who aren’t already familiar not only with deep learning, but also the particular model in question. Additionally the scope of transformations limits users to only affecting five layers (out of eleven), and it’s never stated whether we’re affecting the weights, biases, batch normalization, or some combination. 
My project addresses these user-interface design concerns and implements some of the network bending techniques discussed in these prior works, while adding some new ones.
3	Project
This project is the implementation of network bending on Magenta’s DDSP timbre transfer model and the design of an intuitive and effective user interface. By selecting and interacting with different layers in the network, users can apply transformations to the weights and bias matrices within the network, and listen to the resulting sound. The front end of the application was created using ReactJS, the backend uses python and Flask. The model used was a DDSP autoencoder by Magenta pretrained on flute sounds for timbre transfer, the same as McCallum et al. All transformations were implemented with tensorflow.
Design:
The design process has been an evolution of various prototypes, starting with a figma design in figure 1, along with a prototype implementation to test out applying transformations to different layers in the network using the initial design as a guide. The problem with the initial design was the lack of information regarding what the different layers represented. Ideally the user would be able to know what part of the network they were affecting, for instance, the recurrent weights of the GRU or the bias matrix from the third dense layer. The final version, in figure 2, is the result of various design iterations. It attempts to simplify the visual space while still providing sufficient information about what each component is and the overall state of the system.

Figure 1: First design concept for this project.

The body of the app is made up of various in-line modules representing nine dense layers and one recurrent layer, which make up the decoder portion of Magenta’s DDSP timbre transfer autoencoder network[4]. The purpose of the model is to perform timbre transfer from one instrument to another, and the current implementation takes some audio input and changes its timbre to sound like a flute. The goal of the application is to take this baseline transformation and further manipulate it to make even stranger sounds.
Each layer module contains weights and biases as subcomponents, each with their own set of transformations which can be selected from a dropdown menu. The transformations that have been implemented so far include some that were borrowed from previous works like scalar multiplication (which requires the user to input a number to multiply the matrix with), ablation (which is called zero for simplicity), and inversion. I added some additional transformations including random with min and max inputs, shuffle which is similar to random but it shuffles the existing matrix values to new indices, and identity, which converts the matrix to all ones. Input and output modules display spectrograms of the audio before and after the transformations are applied.
On the left column of the application there are some higher level controls, including a selection of example sounds to try out, a playback tool for affected and original audio, a button to apply the currently selected transformations to the currently selected sound, a ‘clear’ button to reset all transformations, and an undo button that takes you to the previous iteration.

Figure 2: Latest iteration of this project. 
4	Results
My project was able to improve on the interface design compared to previous work in two ways: it provides more scope of the model and it is simpler and more intuitive for beginners. The first point is clear when compared to McCallum’s application as it doesn’t let you specifically target the weights and biases, and restricts users to only manipulating five layers in total. My application, on the other hand, enables users to choose any and all of the eleven fully-connected layers, and target specific matrices within those layers, enabling a total of 23 chained transformations compared to five. The second point is shown in that McCallum’s application, in figure 3, is almost entirely composed of number input forms, and there is no order for how the layers are displayed. My project keeps layers in their respective orders as they appear in the actual model, and keep only the selected transformations visible, the rest being hidden in dropdown menus. My application is mostly point and click (with the exception of a few parameters like scalar multiplication and random min/max), which creates an easy user interface for beginners. Additionally, the use of spectrograms gives  users visual feedback which can help give the feeling that they’re using the application correctly. One way McCallum’s work is better is that it allows users to choose any audio, and generally provides more granularity with a given transformation.

Figure 3: McCallum’s application for network bending
5	Discussion
Overall, my project is effective as a tool for audio creativity as well as for better understanding black box models. After using the app for a few minutes I was able to gain a sense of how different layers were impacting different aspects of the resulting sound. For instance, the early and middle layers had a lot of pitch and temporal impacts while later layers were dynamically impactful. The most interesting layer was definitely the GRU, which could do anything from changing the pitch to adding interesting vibrato. The later layers were extremely sensitive and often led to loud and distorted outputs if the transformations weren’t subtle enough.
While I feel the project was a success there’s still plenty of room for improvement. For instance, users should be able to upload any sounds they want, and there could also be more freedom with model selection both with the encoder and decoder. There’s infinite possibilities for additional transformations that can be added to the repertoire, and also it would be good to have a way to change the amount of each transformation, especially with the later layers that are more sensitive.
The project can be found on my github page along with a short demo: .

References
Broad, T., Leymarie, F.F. & Grierson, M. (2020) Network Bending: Manipulating The Inner Representations of Deep Generative Models, arXiv:2005.12420 [cs.Cv].
Sebastian Berns and Simon Colton. Bridging generative deep learning and computational creativity. In Proceedings of the 11th International Conference on Computational Creativity, 2020.
Louis McCallum and Matthew Yee-King. Network bending neural vocoders. NeurIPS 2020 Workshop on Machine Learning for Creativity and Design, 2020.
Engel, J., Lamtharn, H., Gu, C. & Roberts, A. (2020) DDSP: Differentiable Digital Signal Processing, in Proc. International Conference on Learning Representations 2020.
